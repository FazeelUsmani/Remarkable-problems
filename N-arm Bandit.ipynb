{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TabError",
     "evalue": "inconsistent use of tabs and spaces in indentation (<ipython-input-1-1be6fce5af3c>, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-1be6fce5af3c>\"\u001b[1;36m, line \u001b[1;32m22\u001b[0m\n\u001b[1;33m    Q=np.zeros((n_bandit,k)) # reward estimated\u001b[0m\n\u001b[1;37m                                               ^\u001b[0m\n\u001b[1;31mTabError\u001b[0m\u001b[1;31m:\u001b[0m inconsistent use of tabs and spaces in indentation\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "n_bandit=2000 # number of bandit problems\n",
    "k=10 # number of arms in each bandit problem\n",
    "n_pulls=1000 # number of times to pull each arm\n",
    "\n",
    "q_true=np.random.normal(0,1,(n_bandit,k)) # generating the true means q*(a) for each arm for all bandits\n",
    "true_opt_arms=np.argmax(q_true,1) # the true optimal arms in each bandit\n",
    "# each row represents a bandit problem\n",
    "\n",
    "epsilon=[0,0.01,0.1,0.2,1] # epsilon in epsilon-greedy method\n",
    "col=['r','g','k','b','y']\n",
    "#fig=plt.figure()\n",
    "fig1=plt.figure().add_subplot(111)\n",
    "fig2=plt.figure().add_subplot(111)\n",
    "\n",
    "for eps in range(len(epsilon)) : \n",
    "    print('Current epsilon: ',eps)\n",
    "\n",
    "\tQ=np.zeros((n_bandit,k)) # reward estimated\n",
    "\tN=np.ones((n_bandit,k)) # number of times each arm was pulled # each arm is pulled atleast once\n",
    "\t# Pull all arms once\n",
    "\tQi=np.random.normal(q_true,1) # initial pulling of all arms\n",
    "\n",
    "\tR_eps=[]\n",
    "\tR_eps.append(0)\n",
    "\tR_eps.append(np.mean(Qi))\t\n",
    "\tR_eps_opt=[]\n",
    "\n",
    "\tfor pull in range(2,n_pulls+1) :  \n",
    "\t\tR_pull=[] # all rewards in this pull/time-step\n",
    "\t\topt_arm_pull=0 # number of pulss of best arm in this time step\n",
    "\t\tfor i in range(n_bandit) : \t\n",
    "\n",
    "\t\t\tif random.random()<epsilon[eps] : \n",
    "\t\t\t\tj=np.random.randint(k)\t\t\t\t\t\t\t\t\t\t\t\n",
    "\t\t\telse : \n",
    "\t\t\t\tj=np.argmax(Q[i])\n",
    "\n",
    "\t\t\tif j==true_opt_arms[i] : # To calculate % optimal action\n",
    "\t\t\t\topt_arm_pull=opt_arm_pull+1\n",
    "\n",
    "\t\t\ttemp_R=np.random.normal(q_true[i][j],1)\n",
    "\t\t\tR_pull.append(temp_R)\n",
    "\t\t\tN[i][j]=N[i][j]+1\n",
    "\t\t\tQ[i][j]=Q[i][j]+(temp_R-Q[i][j])/N[i][j]\n",
    "\t\t\n",
    "\t\tavg_R_pull=np.mean(R_pull)\t\t\n",
    "\t\tR_eps.append(avg_R_pull)\n",
    "\t\tR_eps_opt.append(float(opt_arm_pull)*100/2000)\n",
    "\tfig1.plot(range(0,n_pulls+1),R_eps,col[eps])\n",
    "\tfig2.plot(range(2,n_pulls+1),R_eps_opt,col[eps])\n",
    "\n",
    "plt.rc('text',usetex=True)\n",
    "#plt.ylim(0.5,1.5)\n",
    "fig1.title.set_text(r'$\\epsilon$-greedy : Average Reward Vs Steps for 10 arms')\n",
    "fig1.set_ylabel('Average Reward')\n",
    "fig1.set_xlabel('Steps')\n",
    "fig1.legend((r\"$\\epsilon=$\"+str(epsilon[0]),r\"$\\epsilon=$\"+str(epsilon[1]),r\"$\\epsilon=$\"+str(epsilon[2]),r\"$\\epsilon=$\"+str(epsilon[3]),r\"$\\epsilon=$\"+str(epsilon[4])),loc='best')\n",
    "fig2.title.set_text(r'$\\epsilon$-greedy : $\\%$ Optimal Action Vs Steps for 10 arms')\n",
    "fig2.set_ylabel(r'$\\%$ Optimal Action')\n",
    "fig2.set_xlabel('Steps')\n",
    "fig2.set_ylim(0,100)\n",
    "fig2.legend((r\"$\\epsilon=$\"+str(epsilon[0]),r\"$\\epsilon=$\"+str(epsilon[1]),r\"$\\epsilon=$\"+str(epsilon[2]),r\"$\\epsilon=$\"+str(epsilon[3]),r\"$\\epsilon=$\"+str(epsilon[4])),loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
